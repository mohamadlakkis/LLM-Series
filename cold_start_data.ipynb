{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec5bdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "DEEPSEEK_API_KEY = os.getenv(\"DEEPSEEK_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50bbf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://api-docs.deepseek.com/\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=DEEPSEEK_API_KEY,\n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182bc495",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"openai/gsm8k\", \"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77260c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples = ds['train']\n",
    "print(f\"Number of training samples: {len(nb_samples)}\")\n",
    "subset_samples = ds['train'].shuffle(seed=0).select(range(5))\n",
    "print(f\"Number of subset samples: {len(subset_samples)}\")\n",
    "print(f\"Example sample: {subset_samples[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9586ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a mathematician. You will be given a question, and you will provide a step-by-step reasoning process to arrive at the final answer. \n",
    "Before providing the final answer, make sure to think through the problem carefully and show all your work.\n",
    "Your final answer should be \\n#### <answer>\n",
    "\"\"\"\n",
    "USER_PROMPT = \"\"\"\n",
    "Question: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f742543",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_JSON_PATH = \"cold_start_results.jsonl\"\n",
    "\n",
    "for sample in subset_samples:\n",
    "    question = sample['question']\n",
    "    messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": USER_PROMPT.format(question=question)},\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-reasoner\",\n",
    "        messages=messages\n",
    "    )\n",
    "    print(response)\n",
    "    reasoning_content = response.choices[0].message.reasoning_content\n",
    "    actual_answer = response.choices[0].message.content\n",
    "    combined_answer = \"<think>\" + reasoning_content + \"</think>\\n\" + actual_answer\n",
    "    messages.append({\"role\": \"assistant\", \"content\": combined_answer})\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {combined_answer}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "    ## Save the messages to a JSONL file\n",
    "    message_dict = {\n",
    "        \"messages\": messages\n",
    "    }\n",
    "    with open(SAVE_JSON_PATH, \"a\") as f:\n",
    "        f.write(json.dumps(message_dict) + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-series",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
